{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c4c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ab1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torch.from_numpy(np.loadtxt('two_spiral_train_data.txt')).float()\n",
    "data_test = torch.from_numpy(np.loadtxt('two_spiral_test_data.txt')).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3ab25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_ori, batch_size, is_train = True):\n",
    "    data_in = data_ori[:, 0:2]\n",
    "    data_out = data_ori[:, 2]\n",
    "    return data.DataLoader(data.TensorDataset(data_in, data_out), batch_size, shuffle = is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb5dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "data_train_iter = load_data(data_train, batch_size, True)\n",
    "data_test_iter = load_data(data_test, batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12207a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = 2\n",
    "hidden_num = 512\n",
    "output_num = 2\n",
    "\n",
    "u1 = torch.normal(0, 0.01, size = (input_num, hidden_num), requires_grad = True)\n",
    "v1 = torch.normal(0, 0.01, size = (input_num, hidden_num), requires_grad = True)\n",
    "b1 = torch.zeros(hidden_num, requires_grad=True)\n",
    "\n",
    "u2 = torch.normal(0, 0.01, size = (hidden_num, output_num), requires_grad = True)\n",
    "v2 = torch.normal(0, 0.01, size = (hidden_num, output_num), requires_grad = True)\n",
    "b2 = torch.zeros(output_num, requires_grad=True)\n",
    "\n",
    "# parameters with highest accuracy rate\n",
    "u1_max = torch.normal(0, 0.01, size = (input_num, hidden_num), requires_grad = True)\n",
    "v1_max = torch.normal(0, 0.01, size = (input_num, hidden_num), requires_grad = True)\n",
    "b1_max = torch.zeros(hidden_num, requires_grad=True)\n",
    "\n",
    "u2_max = torch.normal(0, 0.01, size = (hidden_num, output_num), requires_grad = True)\n",
    "v2_max = torch.normal(0, 0.01, size = (hidden_num, output_num), requires_grad = True)\n",
    "b2_max = torch.zeros(output_num, requires_grad=True)\n",
    "\n",
    "#print(u1, v1, b1, u2, v2, b2)\n",
    "\n",
    "def quadratic_layer(u, v, b, x):\n",
    "    return torch.matmul(x**2, u) + torch.matmul(x, v) + b\n",
    "\n",
    "def sigmoid(x):\n",
    "    x_exp = torch.exp(-x)\n",
    "    return 1 / (1 + x_exp)\n",
    "\n",
    "def softmax(x):\n",
    "    x_max = torch.max(x)\n",
    "    x_exp = torch.exp(x - x_max)\n",
    "    partition = x_exp.sum(1, keepdim=True)\n",
    "    return x_exp / partition\n",
    "\n",
    "def mlqp(x, u1, v1, b1, u2, v2, b2):\n",
    "    out1 = sigmoid(quadratic_layer(u1, v1, b1, x))\n",
    "    out2 = quadratic_layer(u2, v2, b2, out1)\n",
    "    return softmax(out2)\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -1 * torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            #print(param.grad)\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "\n",
    "#net = nn.Sequential(nn.Linear(input_num, hidden_num), nn.Sigmoid(), nn.Linear(hidden_num, output_num), nn.Sigmoid())\n",
    "\n",
    "#def weight_init(layer):\n",
    "#    if type(layer) == nn.Linear:\n",
    "#        nn.init.normal_(layer.weight, std = 1)\n",
    "        \n",
    "#net.apply(weight_init)\n",
    "#net = net.float()\n",
    "#for parameter in net.parameters():\n",
    "#    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60026afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epoch_num = 1000\n",
    "#loss = nn.CrossEntropyLoss(reduction='none')\n",
    "#updater = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "net = mlqp\n",
    "loss = cross_entropy\n",
    "updater = sgd\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_spiral(net, train_iter, loss, updater, epoch_num, lr, batch_size):\n",
    "    accuracy_max = 0\n",
    "    for i in range(epoch_num):\n",
    "        accuracy_rate = [0., 0., 0.] # loss, predict right, num\n",
    "        for x, y in train_iter:\n",
    "            y_hat = net(x, u1, v1, b1, u2, v2, b2)\n",
    "            #print(y.long())\n",
    "            l = loss(y_hat, y.long())\n",
    "            #print(l)\n",
    "            #updater.zero_grad()\n",
    "            l.sum().backward()\n",
    "            #updater.step()\n",
    "            updater([u1, v1, b1, u2, v2, b2], lr, batch_size)\n",
    "            accuracy_rate[0] = accuracy_rate[0] + l.sum()\n",
    "            accuracy_rate[1] = accuracy_rate[1] + accuracy(y_hat, y)\n",
    "            accuracy_rate[2] = accuracy_rate[2] + y.numel()\n",
    "        accuracy_now = accuracy_rate[1] / accuracy_rate[2]\n",
    "        if accuracy_now > accuracy_max:\n",
    "            accuracy_max = accuracy_now\n",
    "            print('max accuracy:', accuracy_max)\n",
    "            u1_max, v1_max, b1_max, u2_max, v2_max, b2_max = u1 * 1, v1 * 1, b1 * 1, u2 * 1, v2 * 1, b2 * 1\n",
    "        print('loss: {0}, accuracy: {1}'.format(accuracy_rate[0] / accuracy_rate[2], accuracy_rate[1] / accuracy_rate[2]))\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "def plot_decision_boundary(x, y_hat, color = ['b', 'r']):\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    col = []\n",
    "    for i in range(0, len(y_hat)):\n",
    "        col.append(color[y_hat[i]])\n",
    "    plt.scatter(x[:, 0], x[:, 1], c = col)\n",
    "    \n",
    "def evaluate_spiral(net, test_iter, u1_g, v1_g, b1_g, u2_g, v2_g, b2_g):\n",
    "    accuracy_rate = [0., 0.]\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_iter:\n",
    "            y_hat = net(x, u1_g, v1_g, b1_g, u2_g, v2_g, b2_g)\n",
    "            plot_decision_boundary(x, y_hat)\n",
    "            accuracy_rate[0] = accuracy_rate[0] + accuracy(y_hat, y)\n",
    "            accuracy_rate[1] = accuracy_rate[1] + y.numel()\n",
    "    print('accuracy: {0}'.format(accuracy_rate[0] / accuracy_rate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fa8a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy: 0.4866666666666667\n",
      "loss: 3.163512945175171, accuracy: 0.4866666666666667\n",
      "max accuracy: 0.52\n",
      "loss: 2.1971371173858643, accuracy: 0.52\n",
      "max accuracy: 0.5566666666666666\n",
      "loss: 1.581972599029541, accuracy: 0.5566666666666666\n",
      "loss: 1.4979257583618164, accuracy: 0.5366666666666666\n",
      "loss: 1.290783405303955, accuracy: 0.5366666666666666\n",
      "loss: 1.2304677963256836, accuracy: 0.5\n",
      "loss: 0.9773213863372803, accuracy: 0.55\n",
      "loss: 1.3456387519836426, accuracy: 0.47333333333333333\n",
      "loss: 1.0937180519104004, accuracy: 0.5066666666666667\n",
      "loss: 1.079857349395752, accuracy: 0.54\n",
      "max accuracy: 0.5966666666666667\n",
      "loss: 0.9479620456695557, accuracy: 0.5966666666666667\n",
      "loss: 1.0225417613983154, accuracy: 0.5033333333333333\n",
      "loss: 1.1807082891464233, accuracy: 0.5033333333333333\n",
      "loss: 0.8744181394577026, accuracy: 0.5566666666666666\n",
      "loss: 1.027588129043579, accuracy: 0.5366666666666666\n",
      "loss: 0.9095375537872314, accuracy: 0.5233333333333333\n",
      "loss: 0.693103551864624, accuracy: 0.5433333333333333\n",
      "loss: 1.028337001800537, accuracy: 0.5133333333333333\n",
      "loss: 0.8799678683280945, accuracy: 0.5566666666666666\n",
      "loss: 0.9337570071220398, accuracy: 0.54\n",
      "loss: 1.1864758729934692, accuracy: 0.4633333333333333\n",
      "loss: 1.00264310836792, accuracy: 0.5\n",
      "loss: 0.740924596786499, accuracy: 0.57\n",
      "loss: 0.8075590133666992, accuracy: 0.5266666666666666\n",
      "loss: 0.7406496405601501, accuracy: 0.5433333333333333\n",
      "loss: 0.737112283706665, accuracy: 0.5166666666666667\n",
      "loss: 0.8425436615943909, accuracy: 0.4666666666666667\n",
      "loss: 0.7748470306396484, accuracy: 0.5533333333333333\n",
      "loss: 0.764258086681366, accuracy: 0.5433333333333333\n",
      "loss: 1.128540277481079, accuracy: 0.43333333333333335\n",
      "loss: 0.7325227856636047, accuracy: 0.5833333333333334\n",
      "loss: 0.9603519439697266, accuracy: 0.5\n",
      "loss: 0.8251162767410278, accuracy: 0.5133333333333333\n",
      "loss: 0.8243343234062195, accuracy: 0.48333333333333334\n",
      "loss: 0.7002078890800476, accuracy: 0.5566666666666666\n",
      "loss: 0.8856692314147949, accuracy: 0.5233333333333333\n",
      "loss: 1.004801869392395, accuracy: 0.48333333333333334\n",
      "loss: 0.9775895476341248, accuracy: 0.5233333333333333\n",
      "loss: 0.8620275855064392, accuracy: 0.49333333333333335\n",
      "loss: 0.7415945529937744, accuracy: 0.5266666666666666\n",
      "loss: 0.8663567304611206, accuracy: 0.52\n",
      "loss: 0.7235698103904724, accuracy: 0.56\n",
      "loss: 0.8510345816612244, accuracy: 0.5366666666666666\n",
      "loss: 0.9290050268173218, accuracy: 0.48\n",
      "loss: 0.8610820770263672, accuracy: 0.5\n",
      "loss: 0.8507151007652283, accuracy: 0.5166666666666667\n",
      "loss: 0.7806971669197083, accuracy: 0.5366666666666666\n",
      "loss: 0.8114631772041321, accuracy: 0.5133333333333333\n",
      "loss: 0.9245891571044922, accuracy: 0.49333333333333335\n",
      "loss: 0.7246481776237488, accuracy: 0.5466666666666666\n",
      "loss: 0.8519673943519592, accuracy: 0.5133333333333333\n",
      "loss: 0.9040794968605042, accuracy: 0.5233333333333333\n",
      "loss: 0.9218148589134216, accuracy: 0.5033333333333333\n",
      "loss: 0.7239059805870056, accuracy: 0.5533333333333333\n",
      "loss: 0.9505386352539062, accuracy: 0.47333333333333333\n",
      "loss: 0.7653983235359192, accuracy: 0.5\n",
      "loss: 0.8047711253166199, accuracy: 0.52\n",
      "loss: 0.8582313060760498, accuracy: 0.4533333333333333\n",
      "loss: 0.8684462308883667, accuracy: 0.52\n",
      "loss: 0.9540774822235107, accuracy: 0.49333333333333335\n",
      "loss: 0.8228844404220581, accuracy: 0.48\n",
      "loss: 0.6982446908950806, accuracy: 0.52\n",
      "loss: 0.7576154470443726, accuracy: 0.49666666666666665\n",
      "loss: 0.7610600590705872, accuracy: 0.53\n",
      "loss: 0.8269838690757751, accuracy: 0.54\n",
      "loss: 0.7622837424278259, accuracy: 0.5233333333333333\n",
      "loss: 0.8881884813308716, accuracy: 0.47333333333333333\n",
      "loss: 0.8345427513122559, accuracy: 0.5666666666666667\n",
      "loss: 1.0011025667190552, accuracy: 0.4633333333333333\n",
      "loss: 0.7830905914306641, accuracy: 0.5433333333333333\n",
      "loss: 0.7274853587150574, accuracy: 0.5333333333333333\n",
      "loss: 0.9280908107757568, accuracy: 0.48\n",
      "loss: 0.806300699710846, accuracy: 0.4866666666666667\n",
      "loss: 0.8165068626403809, accuracy: 0.51\n",
      "loss: 0.7746838927268982, accuracy: 0.52\n",
      "loss: 0.8049322366714478, accuracy: 0.5066666666666667\n",
      "loss: 0.8263423442840576, accuracy: 0.5133333333333333\n",
      "loss: 0.7430619597434998, accuracy: 0.5633333333333334\n",
      "loss: 0.7561097741127014, accuracy: 0.49333333333333335\n",
      "loss: 0.7178613543510437, accuracy: 0.55\n",
      "loss: 0.8059648871421814, accuracy: 0.51\n",
      "loss: 0.7640452980995178, accuracy: 0.58\n",
      "loss: 0.7304120659828186, accuracy: 0.5166666666666667\n",
      "loss: 0.8545002341270447, accuracy: 0.44\n",
      "loss: 0.7602142095565796, accuracy: 0.4766666666666667\n",
      "loss: 0.8431223630905151, accuracy: 0.5266666666666666\n",
      "loss: 0.7785822749137878, accuracy: 0.57\n",
      "loss: 0.7196067571640015, accuracy: 0.5333333333333333\n",
      "loss: 0.7617120146751404, accuracy: 0.5033333333333333\n",
      "loss: 0.7593492865562439, accuracy: 0.4866666666666667\n",
      "loss: 0.8187576532363892, accuracy: 0.5\n",
      "loss: 0.6971284747123718, accuracy: 0.5233333333333333\n",
      "loss: 0.7887468934059143, accuracy: 0.47\n",
      "loss: 0.7616406083106995, accuracy: 0.49\n",
      "loss: 0.7720131278038025, accuracy: 0.5133333333333333\n",
      "loss: 0.8222017288208008, accuracy: 0.5\n",
      "loss: 0.767742395401001, accuracy: 0.5366666666666666\n",
      "loss: 0.7541742920875549, accuracy: 0.5566666666666666\n",
      "loss: 0.710441529750824, accuracy: 0.5433333333333333\n",
      "loss: 0.8112016916275024, accuracy: 0.4766666666666667\n",
      "loss: 0.8423964977264404, accuracy: 0.5066666666666667\n",
      "loss: 0.8401123285293579, accuracy: 0.5066666666666667\n",
      "loss: 0.7848675847053528, accuracy: 0.5\n",
      "loss: 0.7113918662071228, accuracy: 0.5\n",
      "loss: 0.7555662393569946, accuracy: 0.57\n",
      "loss: 0.9349595308303833, accuracy: 0.47333333333333333\n",
      "loss: 0.7463301420211792, accuracy: 0.55\n",
      "loss: 0.8586061596870422, accuracy: 0.5166666666666667\n",
      "loss: 0.7423388957977295, accuracy: 0.5233333333333333\n",
      "loss: 0.7588614821434021, accuracy: 0.4766666666666667\n",
      "loss: 0.7287644743919373, accuracy: 0.5433333333333333\n",
      "loss: 0.766299307346344, accuracy: 0.48333333333333334\n",
      "loss: 0.7146015167236328, accuracy: 0.5133333333333333\n",
      "loss: 0.7102566361427307, accuracy: 0.5466666666666666\n",
      "loss: 0.8227947950363159, accuracy: 0.5333333333333333\n",
      "loss: 0.7366344332695007, accuracy: 0.5233333333333333\n",
      "loss: 0.750973641872406, accuracy: 0.5033333333333333\n",
      "loss: 0.704068660736084, accuracy: 0.5433333333333333\n",
      "loss: 0.7196823358535767, accuracy: 0.51\n",
      "loss: 0.72869873046875, accuracy: 0.5466666666666666\n",
      "loss: 0.7904905676841736, accuracy: 0.57\n",
      "loss: 0.7761711478233337, accuracy: 0.57\n",
      "loss: 0.7524001598358154, accuracy: 0.5133333333333333\n",
      "loss: 0.8207074403762817, accuracy: 0.47\n",
      "loss: 0.7257192134857178, accuracy: 0.5133333333333333\n",
      "loss: 0.6985586881637573, accuracy: 0.49333333333333335\n",
      "loss: 0.7588245868682861, accuracy: 0.5\n",
      "loss: 0.7806658148765564, accuracy: 0.55\n",
      "loss: 0.8299618363380432, accuracy: 0.5\n",
      "loss: 0.7089051604270935, accuracy: 0.5266666666666666\n",
      "loss: 0.7517135143280029, accuracy: 0.52\n",
      "loss: 0.7748218178749084, accuracy: 0.51\n",
      "loss: 0.7191473245620728, accuracy: 0.49666666666666665\n",
      "loss: 0.823127806186676, accuracy: 0.51\n",
      "loss: 0.8012335300445557, accuracy: 0.5266666666666666\n",
      "loss: 0.7394214272499084, accuracy: 0.4766666666666667\n",
      "loss: 0.7134140133857727, accuracy: 0.5133333333333333\n",
      "loss: 0.7177190780639648, accuracy: 0.52\n",
      "loss: 0.7334252595901489, accuracy: 0.5033333333333333\n",
      "loss: 0.7632368206977844, accuracy: 0.5266666666666666\n",
      "loss: 0.7637161016464233, accuracy: 0.5066666666666667\n",
      "loss: 0.6989120244979858, accuracy: 0.54\n",
      "loss: 0.78859943151474, accuracy: 0.49333333333333335\n",
      "loss: 0.7517356872558594, accuracy: 0.49666666666666665\n",
      "loss: 0.7424778938293457, accuracy: 0.5266666666666666\n",
      "loss: 0.7019752860069275, accuracy: 0.5333333333333333\n",
      "loss: 0.7340041399002075, accuracy: 0.52\n",
      "loss: 0.7721917033195496, accuracy: 0.49333333333333335\n",
      "loss: 0.7248774170875549, accuracy: 0.5433333333333333\n",
      "loss: 0.7644528150558472, accuracy: 0.49666666666666665\n",
      "loss: 0.7282493114471436, accuracy: 0.4866666666666667\n",
      "loss: 0.88986736536026, accuracy: 0.48\n",
      "loss: 0.8483550548553467, accuracy: 0.49666666666666665\n",
      "loss: 0.7464573383331299, accuracy: 0.49333333333333335\n",
      "loss: 0.6929954290390015, accuracy: 0.5633333333333334\n",
      "loss: 0.8365679979324341, accuracy: 0.43666666666666665\n",
      "loss: 0.6976000070571899, accuracy: 0.5066666666666667\n",
      "loss: 0.7153673768043518, accuracy: 0.5233333333333333\n",
      "loss: 0.712817907333374, accuracy: 0.5266666666666666\n",
      "loss: 0.7395656108856201, accuracy: 0.53\n",
      "loss: 0.7808766961097717, accuracy: 0.47333333333333333\n",
      "loss: 0.7188870310783386, accuracy: 0.5433333333333333\n",
      "loss: 0.8095149993896484, accuracy: 0.4633333333333333\n",
      "loss: 0.7218713164329529, accuracy: 0.5733333333333334\n",
      "loss: 0.8041999340057373, accuracy: 0.46\n",
      "loss: 0.7038797736167908, accuracy: 0.5366666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7382324934005737, accuracy: 0.5333333333333333\n",
      "loss: 0.7843312621116638, accuracy: 0.49666666666666665\n",
      "loss: 0.7137205004692078, accuracy: 0.5233333333333333\n",
      "loss: 0.7503478527069092, accuracy: 0.5266666666666666\n",
      "loss: 0.6992818117141724, accuracy: 0.5133333333333333\n",
      "loss: 0.7943836450576782, accuracy: 0.47333333333333333\n",
      "loss: 0.7107489705085754, accuracy: 0.5133333333333333\n",
      "loss: 0.7709618806838989, accuracy: 0.51\n",
      "loss: 0.7167810201644897, accuracy: 0.5266666666666666\n",
      "loss: 0.7700427770614624, accuracy: 0.5\n",
      "loss: 0.709930419921875, accuracy: 0.5266666666666666\n",
      "loss: 0.7511037588119507, accuracy: 0.48333333333333334\n",
      "loss: 0.769536554813385, accuracy: 0.51\n",
      "loss: 0.697081983089447, accuracy: 0.5533333333333333\n",
      "loss: 0.6958431005477905, accuracy: 0.5466666666666666\n",
      "loss: 0.7143757343292236, accuracy: 0.5\n",
      "loss: 0.826159656047821, accuracy: 0.5233333333333333\n",
      "loss: 0.7583156228065491, accuracy: 0.49333333333333335\n",
      "loss: 0.7401154041290283, accuracy: 0.5133333333333333\n",
      "loss: 0.7564560174942017, accuracy: 0.5466666666666666\n",
      "loss: 0.7476763725280762, accuracy: 0.5166666666666667\n",
      "loss: 0.7247479557991028, accuracy: 0.5066666666666667\n",
      "loss: 0.7442162036895752, accuracy: 0.5133333333333333\n",
      "loss: 0.7616925239562988, accuracy: 0.51\n",
      "loss: 0.7466180324554443, accuracy: 0.5166666666666667\n",
      "loss: 0.8330292701721191, accuracy: 0.5233333333333333\n",
      "loss: 0.7966029644012451, accuracy: 0.47\n",
      "loss: 0.7437832951545715, accuracy: 0.5166666666666667\n",
      "loss: 0.6969114542007446, accuracy: 0.5433333333333333\n",
      "loss: 0.759009838104248, accuracy: 0.5466666666666666\n",
      "loss: 0.7897079586982727, accuracy: 0.5166666666666667\n",
      "loss: 0.7334870100021362, accuracy: 0.5233333333333333\n",
      "loss: 0.7446778416633606, accuracy: 0.5233333333333333\n",
      "loss: 0.7711657881736755, accuracy: 0.52\n",
      "loss: 0.724744975566864, accuracy: 0.5533333333333333\n",
      "loss: 0.7031373381614685, accuracy: 0.49\n",
      "loss: 0.7895799875259399, accuracy: 0.5033333333333333\n",
      "loss: 0.7076461315155029, accuracy: 0.5133333333333333\n",
      "loss: 0.7326993942260742, accuracy: 0.4866666666666667\n",
      "loss: 0.6977109313011169, accuracy: 0.5266666666666666\n",
      "loss: 0.7363768219947815, accuracy: 0.53\n",
      "loss: 0.7514753937721252, accuracy: 0.49\n",
      "loss: 0.7002155780792236, accuracy: 0.5433333333333333\n",
      "loss: 0.7254976034164429, accuracy: 0.5166666666666667\n",
      "loss: 0.791079580783844, accuracy: 0.51\n",
      "loss: 0.6870574355125427, accuracy: 0.5466666666666666\n",
      "loss: 0.712357759475708, accuracy: 0.5466666666666666\n",
      "loss: 0.7038043141365051, accuracy: 0.55\n",
      "loss: 0.752515435218811, accuracy: 0.47\n",
      "loss: 0.7667189240455627, accuracy: 0.48\n",
      "loss: 0.7383281588554382, accuracy: 0.51\n",
      "loss: 0.7389205694198608, accuracy: 0.54\n",
      "loss: 0.7585049867630005, accuracy: 0.5366666666666666\n",
      "loss: 0.7061994671821594, accuracy: 0.5266666666666666\n",
      "loss: 0.7010322213172913, accuracy: 0.5533333333333333\n",
      "loss: 0.6909826993942261, accuracy: 0.58\n",
      "loss: 0.7126965522766113, accuracy: 0.53\n",
      "loss: 0.7489567995071411, accuracy: 0.52\n",
      "loss: 0.7125512957572937, accuracy: 0.5366666666666666\n",
      "loss: 0.7538358569145203, accuracy: 0.5133333333333333\n",
      "loss: 0.777623176574707, accuracy: 0.49666666666666665\n",
      "loss: 0.7361621260643005, accuracy: 0.4866666666666667\n",
      "loss: 0.6906424760818481, accuracy: 0.5566666666666666\n",
      "loss: 0.6945836544036865, accuracy: 0.54\n",
      "loss: 0.7826571464538574, accuracy: 0.5133333333333333\n",
      "loss: 0.7172561883926392, accuracy: 0.5466666666666666\n",
      "loss: 0.7385963797569275, accuracy: 0.5366666666666666\n",
      "loss: 0.7780167460441589, accuracy: 0.5633333333333334\n",
      "loss: 0.7128446698188782, accuracy: 0.56\n",
      "loss: 0.7157591581344604, accuracy: 0.5366666666666666\n",
      "loss: 0.7368230819702148, accuracy: 0.5433333333333333\n",
      "loss: 0.7241793274879456, accuracy: 0.5366666666666666\n",
      "loss: 0.7078994512557983, accuracy: 0.5533333333333333\n",
      "loss: 0.8265379667282104, accuracy: 0.47333333333333333\n",
      "loss: 0.7173959612846375, accuracy: 0.5366666666666666\n",
      "loss: 0.7243069410324097, accuracy: 0.54\n",
      "loss: 0.7339401245117188, accuracy: 0.5366666666666666\n",
      "loss: 0.749213695526123, accuracy: 0.5366666666666666\n",
      "loss: 0.7026918530464172, accuracy: 0.5633333333333334\n",
      "loss: 0.7485698461532593, accuracy: 0.51\n",
      "loss: 0.783386766910553, accuracy: 0.5\n",
      "loss: 0.7208991646766663, accuracy: 0.5666666666666667\n",
      "loss: 0.7675511240959167, accuracy: 0.49333333333333335\n",
      "loss: 0.7033734321594238, accuracy: 0.54\n",
      "loss: 0.7498849630355835, accuracy: 0.5166666666666667\n",
      "loss: 0.8112878799438477, accuracy: 0.5\n",
      "loss: 0.7005855441093445, accuracy: 0.53\n",
      "loss: 0.7132569551467896, accuracy: 0.5333333333333333\n",
      "loss: 0.7321078181266785, accuracy: 0.5266666666666666\n",
      "loss: 0.7230175733566284, accuracy: 0.56\n",
      "loss: 0.7356950044631958, accuracy: 0.53\n",
      "loss: 0.7174480557441711, accuracy: 0.5633333333333334\n",
      "loss: 0.7074750065803528, accuracy: 0.5333333333333333\n",
      "loss: 0.731330394744873, accuracy: 0.54\n",
      "loss: 0.6872860789299011, accuracy: 0.55\n",
      "loss: 0.7256264090538025, accuracy: 0.55\n",
      "loss: 0.6897408962249756, accuracy: 0.5833333333333334\n",
      "loss: 0.7549015283584595, accuracy: 0.5533333333333333\n",
      "loss: 0.7115873098373413, accuracy: 0.5433333333333333\n",
      "loss: 0.7346004247665405, accuracy: 0.5333333333333333\n",
      "loss: 0.692605197429657, accuracy: 0.5666666666666667\n",
      "loss: 0.6949912309646606, accuracy: 0.5733333333333334\n",
      "loss: 0.7062813639640808, accuracy: 0.5666666666666667\n",
      "loss: 0.7221788763999939, accuracy: 0.5733333333333334\n",
      "loss: 0.7049508690834045, accuracy: 0.55\n",
      "loss: 0.6865909099578857, accuracy: 0.57\n",
      "loss: 0.7281045317649841, accuracy: 0.5266666666666666\n",
      "loss: 0.712367832660675, accuracy: 0.54\n",
      "loss: 0.6919317245483398, accuracy: 0.5366666666666666\n",
      "loss: 0.7881501317024231, accuracy: 0.5166666666666667\n",
      "loss: 0.7227407693862915, accuracy: 0.5533333333333333\n",
      "loss: 0.714478611946106, accuracy: 0.54\n",
      "loss: 0.686784029006958, accuracy: 0.5533333333333333\n",
      "loss: 0.7124189734458923, accuracy: 0.57\n",
      "loss: 0.703191876411438, accuracy: 0.5533333333333333\n",
      "loss: 0.7264531254768372, accuracy: 0.5133333333333333\n",
      "loss: 0.7093566656112671, accuracy: 0.56\n",
      "loss: 0.7538868188858032, accuracy: 0.5333333333333333\n",
      "loss: 0.7062447667121887, accuracy: 0.5633333333333334\n",
      "loss: 0.7094480395317078, accuracy: 0.54\n",
      "loss: 0.7216658592224121, accuracy: 0.53\n",
      "loss: 0.7470319867134094, accuracy: 0.5266666666666666\n",
      "loss: 0.7088242769241333, accuracy: 0.5233333333333333\n",
      "loss: 0.7316469550132751, accuracy: 0.52\n",
      "loss: 0.752590537071228, accuracy: 0.55\n",
      "loss: 0.749169647693634, accuracy: 0.53\n",
      "loss: 0.6938320398330688, accuracy: 0.5666666666666667\n",
      "loss: 0.7977052330970764, accuracy: 0.52\n",
      "loss: 0.7251645922660828, accuracy: 0.5566666666666666\n",
      "loss: 0.7198631167411804, accuracy: 0.58\n",
      "loss: 0.721727728843689, accuracy: 0.55\n",
      "loss: 0.7545375823974609, accuracy: 0.5166666666666667\n",
      "loss: 0.739179253578186, accuracy: 0.5566666666666666\n",
      "loss: 0.7109002470970154, accuracy: 0.55\n",
      "loss: 0.6858946681022644, accuracy: 0.5866666666666667\n",
      "loss: 0.6884051561355591, accuracy: 0.5733333333333334\n",
      "loss: 0.7770756483078003, accuracy: 0.5133333333333333\n",
      "max accuracy: 0.61\n",
      "loss: 0.7049402594566345, accuracy: 0.61\n",
      "loss: 0.6921013593673706, accuracy: 0.5666666666666667\n",
      "loss: 0.7099018692970276, accuracy: 0.5566666666666666\n",
      "loss: 0.7328187823295593, accuracy: 0.5366666666666666\n",
      "loss: 0.7305449843406677, accuracy: 0.5333333333333333\n",
      "loss: 0.688147783279419, accuracy: 0.5666666666666667\n",
      "loss: 0.7473248243331909, accuracy: 0.5066666666666667\n",
      "loss: 0.7072710394859314, accuracy: 0.5566666666666666\n",
      "loss: 0.7046924829483032, accuracy: 0.5433333333333333\n",
      "loss: 0.6523132920265198, accuracy: 0.5766666666666667\n",
      "loss: 0.701416552066803, accuracy: 0.5466666666666666\n",
      "loss: 0.7212744951248169, accuracy: 0.5666666666666667\n",
      "loss: 0.6862390041351318, accuracy: 0.5833333333333334\n",
      "loss: 0.7062442302703857, accuracy: 0.56\n",
      "loss: 0.7499013543128967, accuracy: 0.5233333333333333\n",
      "loss: 0.8030481934547424, accuracy: 0.49\n",
      "loss: 0.684297502040863, accuracy: 0.5766666666666667\n",
      "loss: 0.7159914374351501, accuracy: 0.5666666666666667\n",
      "loss: 0.6914559006690979, accuracy: 0.5233333333333333\n",
      "loss: 0.7149741649627686, accuracy: 0.5133333333333333\n",
      "loss: 0.7357919216156006, accuracy: 0.5433333333333333\n",
      "loss: 0.6854640245437622, accuracy: 0.5733333333333334\n",
      "loss: 0.7180154323577881, accuracy: 0.5466666666666666\n",
      "loss: 0.693050742149353, accuracy: 0.5533333333333333\n",
      "loss: 0.7392539978027344, accuracy: 0.5233333333333333\n",
      "loss: 0.6927399039268494, accuracy: 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7229570746421814, accuracy: 0.57\n",
      "loss: 0.727479100227356, accuracy: 0.5466666666666666\n",
      "loss: 0.7022575736045837, accuracy: 0.5833333333333334\n",
      "loss: 0.7840574979782104, accuracy: 0.5166666666666667\n",
      "loss: 0.7091957330703735, accuracy: 0.5366666666666666\n",
      "loss: 0.6882911920547485, accuracy: 0.5666666666666667\n",
      "loss: 0.7083090543746948, accuracy: 0.5566666666666666\n",
      "loss: 0.6883193850517273, accuracy: 0.5733333333333334\n",
      "loss: 0.6953931450843811, accuracy: 0.5733333333333334\n",
      "loss: 0.7152614593505859, accuracy: 0.5233333333333333\n",
      "loss: 0.6997359991073608, accuracy: 0.5566666666666666\n",
      "loss: 0.7794039249420166, accuracy: 0.4766666666666667\n",
      "loss: 0.7298280596733093, accuracy: 0.52\n",
      "loss: 0.6902608275413513, accuracy: 0.5833333333333334\n",
      "loss: 0.763546347618103, accuracy: 0.5133333333333333\n",
      "loss: 0.7061020731925964, accuracy: 0.5533333333333333\n",
      "loss: 0.7056173086166382, accuracy: 0.5766666666666667\n",
      "loss: 0.7019459009170532, accuracy: 0.5466666666666666\n",
      "loss: 0.6885644197463989, accuracy: 0.5766666666666667\n",
      "loss: 0.692489743232727, accuracy: 0.5766666666666667\n",
      "loss: 0.6936587691307068, accuracy: 0.5533333333333333\n",
      "loss: 0.7272579073905945, accuracy: 0.5466666666666666\n",
      "loss: 0.6981374025344849, accuracy: 0.54\n",
      "loss: 0.7502992749214172, accuracy: 0.5266666666666666\n",
      "loss: 0.6886070966720581, accuracy: 0.5533333333333333\n",
      "loss: 0.6993906497955322, accuracy: 0.5433333333333333\n",
      "loss: 0.7610149383544922, accuracy: 0.5266666666666666\n",
      "loss: 0.7126638889312744, accuracy: 0.5433333333333333\n",
      "loss: 0.7086751461029053, accuracy: 0.53\n",
      "loss: 0.7243571877479553, accuracy: 0.5466666666666666\n",
      "loss: 0.6915061473846436, accuracy: 0.5666666666666667\n",
      "loss: 0.688122570514679, accuracy: 0.55\n",
      "loss: 0.6769607067108154, accuracy: 0.5966666666666667\n",
      "loss: 0.6874375939369202, accuracy: 0.5933333333333334\n",
      "loss: 0.7363055348396301, accuracy: 0.54\n",
      "loss: 0.6926976442337036, accuracy: 0.58\n",
      "loss: 0.7760575413703918, accuracy: 0.5566666666666666\n",
      "loss: 0.6962610483169556, accuracy: 0.5933333333333334\n",
      "loss: 0.7117205858230591, accuracy: 0.57\n",
      "loss: 0.709761917591095, accuracy: 0.5633333333333334\n",
      "loss: 0.67533278465271, accuracy: 0.5866666666666667\n",
      "loss: 0.6864407062530518, accuracy: 0.5933333333333334\n",
      "loss: 0.7154268026351929, accuracy: 0.56\n",
      "loss: 0.7281953692436218, accuracy: 0.5533333333333333\n",
      "loss: 0.7097066044807434, accuracy: 0.5933333333333334\n",
      "loss: 0.6986123323440552, accuracy: 0.59\n",
      "loss: 0.6981058716773987, accuracy: 0.5533333333333333\n",
      "loss: 0.6772822141647339, accuracy: 0.5733333333333334\n",
      "loss: 0.6825323104858398, accuracy: 0.5866666666666667\n",
      "loss: 0.7113575339317322, accuracy: 0.5733333333333334\n",
      "loss: 0.6779264807701111, accuracy: 0.5866666666666667\n",
      "loss: 0.6959529519081116, accuracy: 0.5766666666666667\n",
      "loss: 0.6831748485565186, accuracy: 0.5666666666666667\n",
      "loss: 0.718731701374054, accuracy: 0.5466666666666666\n",
      "loss: 0.6788774728775024, accuracy: 0.5933333333333334\n",
      "loss: 0.6863675117492676, accuracy: 0.59\n",
      "loss: 0.7403280138969421, accuracy: 0.5633333333333334\n",
      "loss: 0.7264307737350464, accuracy: 0.57\n",
      "loss: 0.7141516208648682, accuracy: 0.5366666666666666\n",
      "loss: 0.7281789779663086, accuracy: 0.5733333333333334\n",
      "loss: 0.6967895030975342, accuracy: 0.5733333333333334\n",
      "loss: 0.688876748085022, accuracy: 0.6033333333333334\n",
      "loss: 0.6731483936309814, accuracy: 0.5766666666666667\n",
      "loss: 0.6907084584236145, accuracy: 0.5433333333333333\n",
      "loss: 0.720398485660553, accuracy: 0.54\n",
      "loss: 0.6938071846961975, accuracy: 0.5833333333333334\n",
      "loss: 0.7488414645195007, accuracy: 0.5233333333333333\n",
      "loss: 0.6769108772277832, accuracy: 0.5833333333333334\n",
      "loss: 0.6883681416511536, accuracy: 0.5866666666666667\n",
      "loss: 0.6955113410949707, accuracy: 0.56\n",
      "loss: 0.696153998374939, accuracy: 0.5766666666666667\n",
      "loss: 0.7235007286071777, accuracy: 0.55\n",
      "loss: 0.75726318359375, accuracy: 0.5433333333333333\n",
      "loss: 0.6952464580535889, accuracy: 0.5866666666666667\n",
      "loss: 0.693088710308075, accuracy: 0.5766666666666667\n",
      "loss: 0.734988808631897, accuracy: 0.5466666666666666\n",
      "max accuracy: 0.6366666666666667\n",
      "loss: 0.6403055191040039, accuracy: 0.6366666666666667\n",
      "loss: 0.6962671279907227, accuracy: 0.6033333333333334\n",
      "loss: 0.7301222681999207, accuracy: 0.5466666666666666\n",
      "loss: 0.7379963397979736, accuracy: 0.55\n",
      "loss: 0.7212170958518982, accuracy: 0.5966666666666667\n",
      "loss: 0.7040085792541504, accuracy: 0.59\n",
      "loss: 0.6855321526527405, accuracy: 0.5866666666666667\n",
      "loss: 0.691206693649292, accuracy: 0.5733333333333334\n",
      "loss: 0.698561429977417, accuracy: 0.5666666666666667\n",
      "loss: 0.6931059956550598, accuracy: 0.5666666666666667\n",
      "loss: 0.6940120458602905, accuracy: 0.5966666666666667\n",
      "loss: 0.7232254147529602, accuracy: 0.59\n",
      "loss: 0.6703693866729736, accuracy: 0.6066666666666667\n",
      "loss: 0.6776976585388184, accuracy: 0.58\n",
      "loss: 0.7306686639785767, accuracy: 0.5533333333333333\n",
      "loss: 0.6933302879333496, accuracy: 0.57\n",
      "loss: 0.7495794892311096, accuracy: 0.5533333333333333\n",
      "loss: 0.7081250548362732, accuracy: 0.54\n",
      "loss: 0.6855066418647766, accuracy: 0.58\n",
      "loss: 0.7362839579582214, accuracy: 0.56\n",
      "loss: 0.67095547914505, accuracy: 0.5933333333333334\n",
      "loss: 0.7358469367027283, accuracy: 0.5766666666666667\n",
      "loss: 0.6925147771835327, accuracy: 0.5633333333333334\n",
      "loss: 0.6846598386764526, accuracy: 0.5566666666666666\n",
      "loss: 0.6924338340759277, accuracy: 0.6066666666666667\n",
      "loss: 0.7130142450332642, accuracy: 0.5666666666666667\n",
      "loss: 0.7248204350471497, accuracy: 0.5566666666666666\n",
      "loss: 0.7072516083717346, accuracy: 0.59\n",
      "loss: 0.694093644618988, accuracy: 0.5566666666666666\n",
      "loss: 0.7189610004425049, accuracy: 0.56\n",
      "loss: 0.7182758450508118, accuracy: 0.57\n",
      "loss: 0.6733535528182983, accuracy: 0.5666666666666667\n",
      "loss: 0.6642409563064575, accuracy: 0.5733333333333334\n",
      "loss: 0.6695632338523865, accuracy: 0.5766666666666667\n",
      "loss: 0.7035433053970337, accuracy: 0.55\n",
      "loss: 0.6706790924072266, accuracy: 0.6066666666666667\n",
      "loss: 0.6755503416061401, accuracy: 0.6133333333333333\n",
      "loss: 0.6459553837776184, accuracy: 0.63\n",
      "loss: 0.6683325171470642, accuracy: 0.5966666666666667\n",
      "loss: 0.6988096833229065, accuracy: 0.5733333333333334\n",
      "loss: 0.6993038654327393, accuracy: 0.5566666666666666\n",
      "loss: 0.7300693988800049, accuracy: 0.5433333333333333\n",
      "loss: 0.6911060810089111, accuracy: 0.5633333333333334\n",
      "loss: 0.6884598135948181, accuracy: 0.61\n",
      "loss: 0.6843605041503906, accuracy: 0.5966666666666667\n",
      "loss: 0.8007775545120239, accuracy: 0.52\n",
      "loss: 0.6620039939880371, accuracy: 0.61\n",
      "loss: 0.7108679413795471, accuracy: 0.5766666666666667\n",
      "loss: 0.6661107540130615, accuracy: 0.6\n",
      "loss: 0.6837038993835449, accuracy: 0.5933333333333334\n",
      "loss: 0.6770548224449158, accuracy: 0.5666666666666667\n",
      "loss: 0.6931484937667847, accuracy: 0.6\n",
      "loss: 0.6857977509498596, accuracy: 0.5733333333333334\n",
      "loss: 0.6850558519363403, accuracy: 0.5766666666666667\n",
      "loss: 0.6683908700942993, accuracy: 0.5866666666666667\n",
      "loss: 0.7466937303543091, accuracy: 0.56\n",
      "loss: 0.6776512265205383, accuracy: 0.5766666666666667\n",
      "loss: 0.7825725078582764, accuracy: 0.5433333333333333\n",
      "loss: 0.6850442290306091, accuracy: 0.56\n",
      "loss: 0.6668182611465454, accuracy: 0.5866666666666667\n",
      "loss: 0.6819067001342773, accuracy: 0.5466666666666666\n",
      "loss: 0.6958746314048767, accuracy: 0.5666666666666667\n",
      "loss: 0.6855875253677368, accuracy: 0.5933333333333334\n",
      "loss: 0.6714281439781189, accuracy: 0.5633333333333334\n",
      "loss: 0.7963209748268127, accuracy: 0.5\n",
      "loss: 0.7045086026191711, accuracy: 0.5466666666666666\n",
      "loss: 0.7041543126106262, accuracy: 0.5866666666666667\n",
      "loss: 0.675830602645874, accuracy: 0.57\n",
      "loss: 0.7028688788414001, accuracy: 0.61\n",
      "loss: 0.6779893040657043, accuracy: 0.5733333333333334\n",
      "loss: 0.6634488105773926, accuracy: 0.5966666666666667\n",
      "loss: 0.7206667065620422, accuracy: 0.5366666666666666\n",
      "loss: 0.6875643134117126, accuracy: 0.57\n",
      "loss: 0.6986075639724731, accuracy: 0.59\n",
      "loss: 0.7052127122879028, accuracy: 0.5733333333333334\n",
      "loss: 0.6762658953666687, accuracy: 0.5766666666666667\n",
      "loss: 0.6973462700843811, accuracy: 0.5666666666666667\n",
      "loss: 0.6741329431533813, accuracy: 0.57\n",
      "loss: 0.6928768157958984, accuracy: 0.56\n",
      "loss: 0.696011483669281, accuracy: 0.59\n",
      "loss: 0.6705136895179749, accuracy: 0.6033333333333334\n",
      "loss: 0.6921576261520386, accuracy: 0.58\n",
      "loss: 0.6621828675270081, accuracy: 0.5966666666666667\n",
      "loss: 0.6670821905136108, accuracy: 0.6\n",
      "loss: 0.7364605069160461, accuracy: 0.5433333333333333\n",
      "loss: 0.6691201329231262, accuracy: 0.5566666666666666\n",
      "loss: 0.7145828604698181, accuracy: 0.5433333333333333\n",
      "loss: 0.682411789894104, accuracy: 0.56\n",
      "loss: 0.7263960242271423, accuracy: 0.57\n",
      "loss: 0.6956434845924377, accuracy: 0.5733333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6769399642944336, accuracy: 0.5833333333333334\n",
      "loss: 0.6854764819145203, accuracy: 0.5733333333333334\n",
      "loss: 0.6775282025337219, accuracy: 0.5966666666666667\n",
      "loss: 0.7179380059242249, accuracy: 0.5666666666666667\n",
      "loss: 0.6869156956672668, accuracy: 0.57\n",
      "loss: 0.7535749077796936, accuracy: 0.54\n",
      "loss: 0.6764092445373535, accuracy: 0.5933333333333334\n",
      "loss: 0.7077074646949768, accuracy: 0.5533333333333333\n",
      "loss: 0.6814819574356079, accuracy: 0.6\n",
      "loss: 0.6901599764823914, accuracy: 0.5566666666666666\n",
      "loss: 0.6759576797485352, accuracy: 0.59\n",
      "loss: 0.6808868646621704, accuracy: 0.58\n",
      "loss: 0.6893251538276672, accuracy: 0.5566666666666666\n",
      "loss: 0.6907371878623962, accuracy: 0.5633333333333334\n",
      "loss: 0.7002549171447754, accuracy: 0.5666666666666667\n",
      "loss: 0.7136695384979248, accuracy: 0.5533333333333333\n",
      "loss: 0.7302305698394775, accuracy: 0.5633333333333334\n",
      "loss: 0.6980434060096741, accuracy: 0.5933333333333334\n",
      "loss: 0.6742379069328308, accuracy: 0.5633333333333334\n",
      "loss: 0.6752834916114807, accuracy: 0.58\n",
      "loss: 0.6711379885673523, accuracy: 0.56\n",
      "loss: 0.665352463722229, accuracy: 0.59\n",
      "loss: 0.6898561716079712, accuracy: 0.5666666666666667\n",
      "loss: 0.6993569731712341, accuracy: 0.56\n",
      "loss: 0.6829261183738708, accuracy: 0.5833333333333334\n",
      "loss: 0.7165871858596802, accuracy: 0.5833333333333334\n",
      "loss: 0.6781044006347656, accuracy: 0.5833333333333334\n",
      "loss: 0.7372187376022339, accuracy: 0.54\n",
      "loss: 0.690624475479126, accuracy: 0.54\n",
      "loss: 0.6850391030311584, accuracy: 0.5833333333333334\n",
      "loss: 0.6681616306304932, accuracy: 0.5866666666666667\n",
      "loss: 0.7181462645530701, accuracy: 0.52\n",
      "loss: 0.6652321219444275, accuracy: 0.59\n",
      "loss: 0.6692532896995544, accuracy: 0.59\n",
      "loss: 0.6796770095825195, accuracy: 0.58\n",
      "loss: 0.6845778226852417, accuracy: 0.5666666666666667\n",
      "loss: 0.6718709468841553, accuracy: 0.5966666666666667\n",
      "loss: 0.6825260519981384, accuracy: 0.5633333333333334\n",
      "loss: 0.7020444869995117, accuracy: 0.6033333333333334\n",
      "loss: 0.6910956501960754, accuracy: 0.5733333333333334\n",
      "loss: 0.6792396306991577, accuracy: 0.59\n",
      "loss: 0.6809850335121155, accuracy: 0.5733333333333334\n",
      "loss: 0.6618301272392273, accuracy: 0.59\n",
      "loss: 0.6751344799995422, accuracy: 0.56\n",
      "loss: 0.6702617406845093, accuracy: 0.58\n",
      "loss: 0.6776184439659119, accuracy: 0.5833333333333334\n",
      "loss: 0.6819047331809998, accuracy: 0.56\n",
      "loss: 0.6574537754058838, accuracy: 0.6166666666666667\n",
      "loss: 0.680976390838623, accuracy: 0.57\n",
      "loss: 0.6633961200714111, accuracy: 0.58\n",
      "loss: 0.6620240211486816, accuracy: 0.59\n",
      "loss: 0.6575818657875061, accuracy: 0.6133333333333333\n",
      "loss: 0.726057767868042, accuracy: 0.56\n",
      "loss: 0.6598283052444458, accuracy: 0.5966666666666667\n",
      "loss: 0.6762362122535706, accuracy: 0.5633333333333334\n",
      "loss: 0.6790287494659424, accuracy: 0.5433333333333333\n",
      "loss: 0.7178265452384949, accuracy: 0.5566666666666666\n",
      "loss: 0.7075837254524231, accuracy: 0.5366666666666666\n",
      "loss: 0.6675118803977966, accuracy: 0.5766666666666667\n",
      "loss: 0.6711204051971436, accuracy: 0.5833333333333334\n",
      "loss: 0.663605272769928, accuracy: 0.5966666666666667\n",
      "loss: 0.7010865807533264, accuracy: 0.5466666666666666\n",
      "loss: 0.6767838001251221, accuracy: 0.58\n",
      "loss: 0.6489656567573547, accuracy: 0.6033333333333334\n",
      "loss: 0.6710439324378967, accuracy: 0.57\n",
      "loss: 0.6636396050453186, accuracy: 0.5866666666666667\n",
      "loss: 0.6920455694198608, accuracy: 0.56\n",
      "loss: 0.6758670210838318, accuracy: 0.58\n",
      "loss: 0.6700430512428284, accuracy: 0.5366666666666666\n",
      "loss: 0.6676365733146667, accuracy: 0.6\n",
      "loss: 0.6808750629425049, accuracy: 0.5633333333333334\n",
      "loss: 0.6767551898956299, accuracy: 0.5933333333333334\n",
      "loss: 0.6799630522727966, accuracy: 0.62\n",
      "loss: 0.6974396705627441, accuracy: 0.5533333333333333\n",
      "loss: 0.6684345006942749, accuracy: 0.6033333333333334\n",
      "loss: 0.6439907550811768, accuracy: 0.6033333333333334\n",
      "loss: 0.6965226531028748, accuracy: 0.5433333333333333\n",
      "loss: 0.7031271457672119, accuracy: 0.5433333333333333\n",
      "loss: 0.6712538599967957, accuracy: 0.58\n",
      "loss: 0.6920249462127686, accuracy: 0.58\n",
      "loss: 0.6860044002532959, accuracy: 0.55\n",
      "loss: 0.6868560314178467, accuracy: 0.5466666666666666\n",
      "loss: 0.6843714714050293, accuracy: 0.57\n",
      "loss: 0.6681801080703735, accuracy: 0.58\n",
      "loss: 0.7252105474472046, accuracy: 0.57\n",
      "loss: 0.6545398831367493, accuracy: 0.6033333333333334\n",
      "loss: 0.6576626300811768, accuracy: 0.61\n",
      "loss: 0.6521739959716797, accuracy: 0.6133333333333333\n",
      "loss: 0.6809282898902893, accuracy: 0.5633333333333334\n",
      "loss: 0.6681607961654663, accuracy: 0.57\n",
      "loss: 0.6583420038223267, accuracy: 0.59\n",
      "loss: 0.6552169322967529, accuracy: 0.6066666666666667\n",
      "loss: 0.6537566184997559, accuracy: 0.6166666666666667\n",
      "loss: 0.7664607167243958, accuracy: 0.5766666666666667\n",
      "loss: 0.6725940108299255, accuracy: 0.61\n",
      "loss: 0.6583433747291565, accuracy: 0.61\n",
      "loss: 0.660874605178833, accuracy: 0.5966666666666667\n",
      "loss: 0.7000841498374939, accuracy: 0.57\n",
      "loss: 0.6542612314224243, accuracy: 0.62\n",
      "loss: 0.7237411737442017, accuracy: 0.5633333333333334\n",
      "loss: 0.6850641369819641, accuracy: 0.5666666666666667\n",
      "loss: 0.6564834713935852, accuracy: 0.61\n",
      "loss: 0.6591218113899231, accuracy: 0.61\n",
      "loss: 0.6678941249847412, accuracy: 0.5933333333333334\n",
      "loss: 0.6619009375572205, accuracy: 0.5566666666666666\n",
      "loss: 0.6499252319335938, accuracy: 0.5833333333333334\n",
      "loss: 0.7094959616661072, accuracy: 0.5333333333333333\n",
      "loss: 0.6552313566207886, accuracy: 0.6\n",
      "loss: 0.6736572980880737, accuracy: 0.58\n",
      "loss: 0.6750558614730835, accuracy: 0.57\n",
      "loss: 0.6546382904052734, accuracy: 0.61\n",
      "loss: 0.6562309861183167, accuracy: 0.6033333333333334\n",
      "loss: 0.6618432402610779, accuracy: 0.62\n",
      "loss: 0.6881142854690552, accuracy: 0.5566666666666666\n",
      "loss: 0.6605812311172485, accuracy: 0.5733333333333334\n",
      "loss: 0.6583788394927979, accuracy: 0.6033333333333334\n",
      "loss: 0.6566554307937622, accuracy: 0.59\n",
      "loss: 0.6574098467826843, accuracy: 0.6133333333333333\n",
      "loss: 0.6602146625518799, accuracy: 0.5733333333333334\n",
      "loss: 0.6832849979400635, accuracy: 0.61\n",
      "loss: 0.6548163890838623, accuracy: 0.5766666666666667\n",
      "loss: 0.6915762424468994, accuracy: 0.5366666666666666\n",
      "loss: 0.6901347637176514, accuracy: 0.55\n",
      "loss: 0.6590133905410767, accuracy: 0.6033333333333334\n",
      "loss: 0.6502565145492554, accuracy: 0.6233333333333333\n",
      "loss: 0.6645479798316956, accuracy: 0.6\n",
      "loss: 0.6553714871406555, accuracy: 0.6066666666666667\n",
      "loss: 0.6776461005210876, accuracy: 0.5866666666666667\n",
      "loss: 0.6525402069091797, accuracy: 0.58\n",
      "loss: 0.6590505242347717, accuracy: 0.5933333333333334\n",
      "loss: 0.6880858540534973, accuracy: 0.5766666666666667\n",
      "loss: 0.7065847516059875, accuracy: 0.5766666666666667\n",
      "loss: 0.6454355716705322, accuracy: 0.5866666666666667\n",
      "loss: 0.6624366641044617, accuracy: 0.5933333333333334\n",
      "loss: 0.6697676777839661, accuracy: 0.5766666666666667\n",
      "loss: 0.7035149335861206, accuracy: 0.5466666666666666\n",
      "loss: 0.6669791340827942, accuracy: 0.5733333333333334\n",
      "loss: 0.6585490703582764, accuracy: 0.6066666666666667\n",
      "loss: 0.6504572629928589, accuracy: 0.59\n",
      "loss: 0.6612544655799866, accuracy: 0.5866666666666667\n",
      "loss: 0.6759395599365234, accuracy: 0.58\n",
      "loss: 0.6408542990684509, accuracy: 0.62\n",
      "loss: 0.6552226543426514, accuracy: 0.6066666666666667\n",
      "loss: 0.6621303558349609, accuracy: 0.6066666666666667\n",
      "loss: 0.6675786375999451, accuracy: 0.5733333333333334\n",
      "loss: 0.6507591009140015, accuracy: 0.61\n",
      "loss: 0.656684160232544, accuracy: 0.5666666666666667\n",
      "loss: 0.6452849507331848, accuracy: 0.6333333333333333\n",
      "loss: 0.6543616056442261, accuracy: 0.6066666666666667\n",
      "loss: 0.6650108695030212, accuracy: 0.5733333333333334\n",
      "loss: 0.6418311595916748, accuracy: 0.6133333333333333\n",
      "loss: 0.6455632448196411, accuracy: 0.6066666666666667\n",
      "loss: 0.6767410039901733, accuracy: 0.6\n",
      "loss: 0.6493193507194519, accuracy: 0.63\n",
      "loss: 0.6491997241973877, accuracy: 0.5933333333333334\n",
      "loss: 0.6683545112609863, accuracy: 0.5566666666666666\n",
      "loss: 0.6492810249328613, accuracy: 0.63\n",
      "loss: 0.6401380300521851, accuracy: 0.5833333333333334\n",
      "loss: 0.6425014734268188, accuracy: 0.5966666666666667\n",
      "loss: 0.6448058485984802, accuracy: 0.59\n",
      "loss: 0.6736890077590942, accuracy: 0.56\n",
      "loss: 0.6455878615379333, accuracy: 0.6266666666666667\n",
      "loss: 0.6421113610267639, accuracy: 0.6266666666666667\n",
      "loss: 0.6462528705596924, accuracy: 0.6133333333333333\n",
      "loss: 0.6481632590293884, accuracy: 0.6033333333333334\n",
      "loss: 0.655814528465271, accuracy: 0.6066666666666667\n",
      "loss: 0.6741847991943359, accuracy: 0.5633333333333334\n",
      "loss: 0.6481051445007324, accuracy: 0.6333333333333333\n",
      "loss: 0.6564929485321045, accuracy: 0.5866666666666667\n",
      "loss: 0.6743263006210327, accuracy: 0.58\n",
      "loss: 0.6998323798179626, accuracy: 0.5933333333333334\n",
      "loss: 0.6748371124267578, accuracy: 0.56\n",
      "loss: 0.6458450555801392, accuracy: 0.5866666666666667\n",
      "loss: 0.6745766997337341, accuracy: 0.5566666666666666\n",
      "loss: 0.7423571348190308, accuracy: 0.5366666666666666\n",
      "loss: 0.6771595478057861, accuracy: 0.5733333333333334\n",
      "loss: 0.6417863965034485, accuracy: 0.6066666666666667\n",
      "loss: 0.6438127160072327, accuracy: 0.5933333333333334\n",
      "loss: 0.663055956363678, accuracy: 0.5966666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.700964093208313, accuracy: 0.5633333333333334\n",
      "loss: 0.6538360118865967, accuracy: 0.5866666666666667\n",
      "loss: 0.6603221297264099, accuracy: 0.5666666666666667\n",
      "loss: 0.6615008115768433, accuracy: 0.5933333333333334\n",
      "loss: 0.6489700675010681, accuracy: 0.6066666666666667\n",
      "loss: 0.632339358329773, accuracy: 0.6233333333333333\n",
      "loss: 0.6561858654022217, accuracy: 0.6066666666666667\n",
      "loss: 0.6569256782531738, accuracy: 0.5966666666666667\n",
      "loss: 0.6771144866943359, accuracy: 0.5933333333333334\n",
      "loss: 0.6469842195510864, accuracy: 0.61\n",
      "loss: 0.6386103630065918, accuracy: 0.6033333333333334\n",
      "loss: 0.6386860013008118, accuracy: 0.5833333333333334\n",
      "loss: 0.6430243849754333, accuracy: 0.5966666666666667\n",
      "loss: 0.6371374130249023, accuracy: 0.6166666666666667\n",
      "max accuracy: 0.6433333333333333\n",
      "loss: 0.6357094645500183, accuracy: 0.6433333333333333\n",
      "loss: 0.6470019817352295, accuracy: 0.62\n",
      "loss: 0.675106406211853, accuracy: 0.5633333333333334\n",
      "loss: 0.6473168134689331, accuracy: 0.63\n",
      "loss: 0.6830890774726868, accuracy: 0.5833333333333334\n",
      "loss: 0.670684278011322, accuracy: 0.55\n",
      "loss: 0.6374858617782593, accuracy: 0.6166666666666667\n",
      "loss: 0.630312979221344, accuracy: 0.6233333333333333\n",
      "loss: 0.6371166706085205, accuracy: 0.59\n",
      "loss: 0.6606939435005188, accuracy: 0.58\n",
      "loss: 0.633658230304718, accuracy: 0.63\n",
      "loss: 0.6488319635391235, accuracy: 0.6066666666666667\n",
      "loss: 0.6761736273765564, accuracy: 0.57\n",
      "loss: 0.6334654688835144, accuracy: 0.63\n",
      "loss: 0.6348356008529663, accuracy: 0.6266666666666667\n",
      "loss: 0.6831579804420471, accuracy: 0.57\n",
      "loss: 0.6187576055526733, accuracy: 0.6266666666666667\n",
      "loss: 0.6330553293228149, accuracy: 0.6066666666666667\n",
      "loss: 0.6377695202827454, accuracy: 0.62\n",
      "loss: 0.6488804221153259, accuracy: 0.6\n",
      "loss: 0.6499077677726746, accuracy: 0.6166666666666667\n",
      "loss: 0.6538312435150146, accuracy: 0.6033333333333334\n",
      "loss: 0.6472678780555725, accuracy: 0.6\n",
      "loss: 0.6451312899589539, accuracy: 0.6033333333333334\n",
      "loss: 0.6614238619804382, accuracy: 0.6\n",
      "loss: 0.6458495855331421, accuracy: 0.6\n",
      "loss: 0.6693626642227173, accuracy: 0.58\n",
      "loss: 0.6328744888305664, accuracy: 0.5933333333333334\n",
      "loss: 0.6450326442718506, accuracy: 0.6066666666666667\n",
      "loss: 0.6385686993598938, accuracy: 0.61\n",
      "loss: 0.6401014924049377, accuracy: 0.6033333333333334\n",
      "loss: 0.6402863264083862, accuracy: 0.61\n",
      "loss: 0.6608319878578186, accuracy: 0.57\n",
      "loss: 0.6472169756889343, accuracy: 0.6233333333333333\n",
      "loss: 0.6618881821632385, accuracy: 0.5866666666666667\n",
      "loss: 0.6592598557472229, accuracy: 0.5866666666666667\n",
      "loss: 0.6374568343162537, accuracy: 0.61\n",
      "loss: 0.6606586575508118, accuracy: 0.5866666666666667\n",
      "loss: 0.6354663372039795, accuracy: 0.62\n",
      "loss: 0.6276209950447083, accuracy: 0.62\n",
      "max accuracy: 0.65\n",
      "loss: 0.6305002570152283, accuracy: 0.65\n",
      "loss: 0.674111008644104, accuracy: 0.5733333333333334\n",
      "loss: 0.6483389139175415, accuracy: 0.5933333333333334\n",
      "loss: 0.6201674342155457, accuracy: 0.6166666666666667\n",
      "loss: 0.6376222968101501, accuracy: 0.6233333333333333\n",
      "loss: 0.6468239426612854, accuracy: 0.64\n",
      "loss: 0.646584689617157, accuracy: 0.6033333333333334\n",
      "loss: 0.636437714099884, accuracy: 0.63\n",
      "loss: 0.6379985213279724, accuracy: 0.6\n",
      "loss: 0.6396237015724182, accuracy: 0.6066666666666667\n",
      "loss: 0.6201340556144714, accuracy: 0.6166666666666667\n",
      "loss: 0.6559136509895325, accuracy: 0.58\n",
      "loss: 0.6465814113616943, accuracy: 0.6\n",
      "loss: 0.6586824059486389, accuracy: 0.6033333333333334\n",
      "loss: 0.6334088444709778, accuracy: 0.59\n",
      "loss: 0.6272443532943726, accuracy: 0.6133333333333333\n",
      "loss: 0.6363592743873596, accuracy: 0.61\n",
      "loss: 0.6331013441085815, accuracy: 0.61\n",
      "loss: 0.6416763663291931, accuracy: 0.61\n",
      "loss: 0.6278215050697327, accuracy: 0.62\n",
      "loss: 0.6424597501754761, accuracy: 0.6033333333333334\n",
      "loss: 0.6282695531845093, accuracy: 0.6366666666666667\n",
      "loss: 0.6275820136070251, accuracy: 0.64\n",
      "loss: 0.6353132724761963, accuracy: 0.6333333333333333\n",
      "loss: 0.6200737357139587, accuracy: 0.6266666666666667\n",
      "loss: 0.6278757452964783, accuracy: 0.61\n",
      "loss: 0.627799391746521, accuracy: 0.64\n",
      "loss: 0.6301087737083435, accuracy: 0.63\n",
      "loss: 0.6500210165977478, accuracy: 0.6033333333333334\n",
      "loss: 0.6183427572250366, accuracy: 0.6266666666666667\n",
      "loss: 0.6249916553497314, accuracy: 0.62\n",
      "loss: 0.6693307757377625, accuracy: 0.6066666666666667\n",
      "loss: 0.6493228673934937, accuracy: 0.5966666666666667\n",
      "loss: 0.6204566955566406, accuracy: 0.6333333333333333\n",
      "loss: 0.6306576132774353, accuracy: 0.6266666666666667\n",
      "loss: 0.644892692565918, accuracy: 0.6033333333333334\n",
      "loss: 0.6419677138328552, accuracy: 0.5933333333333334\n",
      "loss: 0.6201112270355225, accuracy: 0.6466666666666666\n",
      "loss: 0.6230219602584839, accuracy: 0.6466666666666666\n",
      "loss: 0.6293286085128784, accuracy: 0.6233333333333333\n",
      "loss: 0.6249704360961914, accuracy: 0.6433333333333333\n",
      "loss: 0.6318930983543396, accuracy: 0.59\n",
      "loss: 0.6506547331809998, accuracy: 0.59\n",
      "loss: 0.6226732134819031, accuracy: 0.5833333333333334\n",
      "loss: 0.6739149689674377, accuracy: 0.58\n",
      "loss: 0.6165468096733093, accuracy: 0.62\n",
      "loss: 0.6093668341636658, accuracy: 0.6333333333333333\n",
      "loss: 0.634448230266571, accuracy: 0.5766666666666667\n",
      "loss: 0.6223373413085938, accuracy: 0.6233333333333333\n",
      "loss: 0.6239970922470093, accuracy: 0.6\n",
      "loss: 0.6448071002960205, accuracy: 0.58\n",
      "loss: 0.6337288022041321, accuracy: 0.5933333333333334\n",
      "loss: 0.626064658164978, accuracy: 0.6366666666666667\n",
      "loss: 0.6312370896339417, accuracy: 0.65\n",
      "loss: 0.6424334645271301, accuracy: 0.5966666666666667\n",
      "loss: 0.6224916577339172, accuracy: 0.5966666666666667\n",
      "loss: 0.6278179883956909, accuracy: 0.64\n",
      "loss: 0.6257688999176025, accuracy: 0.6166666666666667\n",
      "loss: 0.6197413802146912, accuracy: 0.6133333333333333\n",
      "loss: 0.6311739087104797, accuracy: 0.6233333333333333\n",
      "loss: 0.6283066868782043, accuracy: 0.6066666666666667\n",
      "loss: 0.6537935137748718, accuracy: 0.5833333333333334\n",
      "loss: 0.6227583289146423, accuracy: 0.6133333333333333\n",
      "max accuracy: 0.6633333333333333\n",
      "loss: 0.6079347133636475, accuracy: 0.6633333333333333\n",
      "loss: 0.6119580864906311, accuracy: 0.6033333333333334\n",
      "loss: 0.6151652932167053, accuracy: 0.6233333333333333\n",
      "loss: 0.6207513213157654, accuracy: 0.6033333333333334\n",
      "loss: 0.6083618402481079, accuracy: 0.63\n",
      "loss: 0.6145356893539429, accuracy: 0.63\n",
      "loss: 0.6176581382751465, accuracy: 0.6466666666666666\n",
      "loss: 0.6296061277389526, accuracy: 0.6133333333333333\n",
      "loss: 0.6025526523590088, accuracy: 0.6333333333333333\n",
      "loss: 0.6163305640220642, accuracy: 0.6233333333333333\n",
      "loss: 0.6176887154579163, accuracy: 0.6133333333333333\n",
      "loss: 0.6029524803161621, accuracy: 0.6433333333333333\n",
      "loss: 0.6396523714065552, accuracy: 0.6\n",
      "loss: 0.6124995350837708, accuracy: 0.6233333333333333\n",
      "loss: 0.618964672088623, accuracy: 0.61\n",
      "loss: 0.6020147800445557, accuracy: 0.6366666666666667\n",
      "loss: 0.5993704795837402, accuracy: 0.65\n",
      "loss: 0.6051977872848511, accuracy: 0.6433333333333333\n",
      "loss: 0.6140252351760864, accuracy: 0.6066666666666667\n",
      "loss: 0.6073832511901855, accuracy: 0.6433333333333333\n",
      "loss: 0.6061330437660217, accuracy: 0.6633333333333333\n",
      "loss: 0.6013922691345215, accuracy: 0.6466666666666666\n",
      "loss: 0.6219920516014099, accuracy: 0.63\n",
      "loss: 0.603804349899292, accuracy: 0.6466666666666666\n",
      "loss: 0.6134055852890015, accuracy: 0.63\n",
      "loss: 0.6017903089523315, accuracy: 0.6266666666666667\n",
      "loss: 0.6009357571601868, accuracy: 0.6333333333333333\n",
      "loss: 0.6101884841918945, accuracy: 0.63\n",
      "loss: 0.5979679226875305, accuracy: 0.6366666666666667\n",
      "loss: 0.5985229015350342, accuracy: 0.6366666666666667\n",
      "loss: 0.6028578281402588, accuracy: 0.6566666666666666\n",
      "loss: 0.6110711097717285, accuracy: 0.62\n",
      "loss: 0.6046857833862305, accuracy: 0.6133333333333333\n",
      "loss: 0.6113060116767883, accuracy: 0.6366666666666667\n",
      "max accuracy: 0.67\n",
      "loss: 0.5931121706962585, accuracy: 0.67\n",
      "loss: 0.6162068843841553, accuracy: 0.6\n",
      "loss: 0.6081805229187012, accuracy: 0.6133333333333333\n",
      "loss: 0.6056676506996155, accuracy: 0.61\n",
      "loss: 0.6073558330535889, accuracy: 0.6366666666666667\n",
      "loss: 0.610884964466095, accuracy: 0.6266666666666667\n",
      "loss: 0.6346649527549744, accuracy: 0.6266666666666667\n",
      "loss: 0.6131570339202881, accuracy: 0.6366666666666667\n",
      "loss: 0.6081262826919556, accuracy: 0.6166666666666667\n",
      "loss: 0.5940783023834229, accuracy: 0.6366666666666667\n",
      "loss: 0.5966688990592957, accuracy: 0.64\n",
      "loss: 0.5949481129646301, accuracy: 0.6433333333333333\n",
      "loss: 0.5984880328178406, accuracy: 0.64\n",
      "loss: 0.6113892197608948, accuracy: 0.63\n",
      "loss: 0.6126495599746704, accuracy: 0.6233333333333333\n",
      "loss: 0.604108452796936, accuracy: 0.5933333333333334\n",
      "loss: 0.6096534729003906, accuracy: 0.6066666666666667\n",
      "loss: 0.5826247930526733, accuracy: 0.6633333333333333\n",
      "loss: 0.597229540348053, accuracy: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5931042432785034, accuracy: 0.6366666666666667\n",
      "loss: 0.597907543182373, accuracy: 0.6533333333333333\n",
      "loss: 0.6067773699760437, accuracy: 0.6233333333333333\n",
      "loss: 0.6292431950569153, accuracy: 0.6033333333333334\n",
      "loss: 0.5962907075881958, accuracy: 0.6133333333333333\n",
      "loss: 0.5982619524002075, accuracy: 0.6166666666666667\n",
      "loss: 0.6028848886489868, accuracy: 0.6533333333333333\n",
      "loss: 0.5841029286384583, accuracy: 0.6433333333333333\n",
      "loss: 0.601743221282959, accuracy: 0.6233333333333333\n",
      "loss: 0.6072644591331482, accuracy: 0.6433333333333333\n",
      "loss: 0.6020748615264893, accuracy: 0.65\n",
      "loss: 0.5880489945411682, accuracy: 0.6533333333333333\n",
      "loss: 0.6025835275650024, accuracy: 0.6266666666666667\n",
      "loss: 0.5953485369682312, accuracy: 0.64\n",
      "loss: 0.5956321358680725, accuracy: 0.64\n",
      "max accuracy: 0.6866666666666666\n",
      "loss: 0.5780876874923706, accuracy: 0.6866666666666666\n",
      "loss: 0.5914298892021179, accuracy: 0.6466666666666666\n",
      "loss: 0.6094202995300293, accuracy: 0.6166666666666667\n",
      "loss: 0.5841502547264099, accuracy: 0.63\n",
      "loss: 0.5913529992103577, accuracy: 0.6466666666666666\n",
      "loss: 0.5951420068740845, accuracy: 0.6433333333333333\n",
      "loss: 0.6010643243789673, accuracy: 0.6433333333333333\n",
      "loss: 0.6010454893112183, accuracy: 0.6366666666666667\n",
      "loss: 0.5822473764419556, accuracy: 0.64\n",
      "loss: 0.5968096852302551, accuracy: 0.6433333333333333\n",
      "loss: 0.5794180631637573, accuracy: 0.66\n",
      "loss: 0.6198177933692932, accuracy: 0.6166666666666667\n",
      "loss: 0.5832759141921997, accuracy: 0.6666666666666666\n",
      "loss: 0.5852228999137878, accuracy: 0.65\n",
      "loss: 0.5914707779884338, accuracy: 0.64\n",
      "loss: 0.5824074149131775, accuracy: 0.6533333333333333\n",
      "loss: 0.5858883857727051, accuracy: 0.6633333333333333\n",
      "loss: 0.5821729898452759, accuracy: 0.63\n",
      "loss: 0.575735330581665, accuracy: 0.6533333333333333\n",
      "loss: 0.594291627407074, accuracy: 0.6333333333333333\n",
      "loss: 0.5854410529136658, accuracy: 0.6666666666666666\n",
      "loss: 0.5816759467124939, accuracy: 0.6366666666666667\n",
      "loss: 0.5977514982223511, accuracy: 0.6266666666666667\n",
      "loss: 0.5802111625671387, accuracy: 0.6733333333333333\n",
      "loss: 0.5862206220626831, accuracy: 0.6466666666666666\n",
      "loss: 0.5937890410423279, accuracy: 0.65\n",
      "loss: 0.5808992981910706, accuracy: 0.6433333333333333\n",
      "loss: 0.5798946022987366, accuracy: 0.6733333333333333\n",
      "loss: 0.582859992980957, accuracy: 0.6666666666666666\n",
      "loss: 0.574630856513977, accuracy: 0.64\n",
      "loss: 0.600097119808197, accuracy: 0.65\n",
      "loss: 0.593610405921936, accuracy: 0.6433333333333333\n",
      "loss: 0.5745484828948975, accuracy: 0.65\n",
      "loss: 0.5793923139572144, accuracy: 0.68\n",
      "loss: 0.5733929872512817, accuracy: 0.67\n",
      "loss: 0.5952947735786438, accuracy: 0.6333333333333333\n",
      "loss: 0.5727221369743347, accuracy: 0.6433333333333333\n",
      "loss: 0.5756158232688904, accuracy: 0.6666666666666666\n",
      "loss: 0.5834594964981079, accuracy: 0.6466666666666666\n",
      "loss: 0.5873321294784546, accuracy: 0.6566666666666666\n",
      "loss: 0.5776626467704773, accuracy: 0.6433333333333333\n",
      "loss: 0.573266327381134, accuracy: 0.6466666666666666\n",
      "loss: 0.5723632574081421, accuracy: 0.6566666666666666\n",
      "loss: 0.5871620178222656, accuracy: 0.64\n",
      "loss: 0.5672066807746887, accuracy: 0.6733333333333333\n",
      "loss: 0.5779193043708801, accuracy: 0.6566666666666666\n",
      "loss: 0.5696077942848206, accuracy: 0.6533333333333333\n",
      "loss: 0.579933226108551, accuracy: 0.65\n",
      "loss: 0.579888105392456, accuracy: 0.6533333333333333\n",
      "loss: 0.574983537197113, accuracy: 0.65\n",
      "loss: 0.5707115530967712, accuracy: 0.6633333333333333\n",
      "loss: 0.5909146666526794, accuracy: 0.64\n",
      "loss: 0.5779178142547607, accuracy: 0.6766666666666666\n",
      "loss: 0.5631575584411621, accuracy: 0.65\n",
      "loss: 0.5677058696746826, accuracy: 0.67\n",
      "loss: 0.5718984007835388, accuracy: 0.66\n",
      "loss: 0.5971660614013672, accuracy: 0.6566666666666666\n",
      "loss: 0.5727939605712891, accuracy: 0.6566666666666666\n",
      "loss: 0.5676295757293701, accuracy: 0.66\n",
      "loss: 0.566136360168457, accuracy: 0.6633333333333333\n",
      "loss: 0.5752434730529785, accuracy: 0.6533333333333333\n",
      "loss: 0.5682795643806458, accuracy: 0.6633333333333333\n",
      "loss: 0.5631983876228333, accuracy: 0.6766666666666666\n",
      "max accuracy: 0.69\n",
      "loss: 0.5589168071746826, accuracy: 0.69\n",
      "loss: 0.565998911857605, accuracy: 0.6633333333333333\n",
      "loss: nan, accuracy: 0.6466666666666666\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "loss: nan, accuracy: 0.53\n",
      "accuracy: 0.47\n",
      "the training time is: 12.056339979171753\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "time_begin = time.time()\n",
    "train_spiral(net, data_train_iter, loss, updater, epoch_num, lr, batch_size)\n",
    "time_end = time.time()\n",
    "evaluate_spiral(net, data_test_iter, u1, v1, b1, u2, v2, b2)\n",
    "\n",
    "print('the training time is:', time_end - time_begin)\n",
    "#print(u1, v1, b1, u2, v2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9fcacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAV40lEQVR4nO3de2xdV5XH8d+K347TpImdOLXdOC1NUYeHAFMNqoYBWqECFZWQQEUCDfBHGDRURapUtVTz/2gYQZGAGaK2aCQqoVF5DCowUASMZoQoOKWltKFJmubhPG/a5tE6fsVr/ti+42vHsR3ffXz2Pef7kaLYx/fuu87Z1+tu73XO2ebuAgA0rjV5BwAAqA+JHAAaHIkcABociRwAGhyJHAAaXHMeL9rd3e2Dg4N5vDQANKzdu3efdvee+dtzSeSDg4MaHh7O46UBoGGZ2aGFtjO1AgANjkQOAA2ORA4ADY5EDgANLpdi50q4S889J50/L91wg/Tii9KWLdLFi9Irr0g7dkh790obN0qtrdLx42Hb/v3SunXh35EjYdvLL0ttbVJ3t3TwoPSmN0kjI+F1+vqkl16Stm+XTp2SJielbdukffuka6+Vzp6VXn89PGfvXqm3V5qYkF57LbT94otST4+0Zo108uRsDFddJXV2SkePzsbQ3i5t2jQbw5EjUlOTtHVriOG666QTJ8I+XnttiGHbNunVV6ULF6Trrw8xXHNN+P7s2dljs3lzOGaVinTjjeFxV18d9rt6bF56SVq7Vlq/Xjp8ODz30CGppSU8/+WXw2scOxba6u8P+7J9e2h3fDx8vXdv+Nnrr4f+qT02U1Nz+2fTJqm5OexXbf90dYU+qO2fnp7wdbV/zMK+LtY/Z85Io6Ozx2br1hDna6+F/du7N7RrFp5/443huevXSx0dYV+rx6azMxyzQ4fCcw8fDv3T2ysdOBBe4/jx0D8DA2FfBgfD/o6NzR6bvr4Q07lzs8dmyxZpenpu/9S+d2+4IcTQ1bV0/xw9Gt671f4ZHJROn57bPwMD4fVr37tbt4b37quvhrb37Qv909Q09727UP8s9N5dsya0eeDA7Ht3amq2f7ZtC/0wOhp+vm9fePzYWOi3av9s3hz259Sp8Hr79kkbNoTXrB6bAwdC/2zYMPfYNDfP9s9114XHT08v3j+1793VyC3XXx++jpwgve5/kjZIelzSXyTtkfSexR7/rne9y6/E/v3uO3a4r13r3tbmLrm3t7ubua9ZM7utrS18bza7rbV1dlt7e9jW0uLe1BS+7ugI/zc3h3/VtqXwmJaWS1+vtXX29a40hurrVWOojau5eTauhWKoPrc2hoXiWurY1B6H+XHVxlDd1tR06bFZs+bSY9PUtPwYYvdPR8fi/VO77UpiWGn/LPa+WW7/LPS+WW7/LPTere2fGO/d2tdbzu/PSt+7K+mf2mMTu3/qee+uXRse+/GPu4+NXVEadA/JdnihnGox7n5oZv8u6X/c/WEza5XU6e5nLvf4oaEhX+7ph9PT4ZP18OEwKgSARtfeLn3+89JDD13Z88xst7sPzd9e9xy5ma2X9F5Jj0iSu08slsSv1G9/G/7MI4kDKIqxMenb346X12IUO7dLqkj6jpn90cweNrO18x9kZjvNbNjMhiuVyrIbP3w47DQAFMnYWJiHjyFGIm+W9E5J/+ru75D0hqT75z/I3Xe5+5C7D/X0XHKF6WXF2lEASI1ZnHZiJPIRSSPu/tTM948rJPYoSOQAiiqZRO7uJyQdMbMbZzbdKumFetutam+P1RIApCXWQDXWeeR3S3ps5oyVA5I+G6ldXbgQqyUASEtzpAwcpRl3f0bSJafExNDamkWrAJC/ixfjJPPkL9Gfns47AgBIW/KJfGoq7wgAIBtNTXHaST6Rd3bmHQEAZCPWQDX5RD46mncEAJCN0ozIY1V1ASA1sWqAySfyNclHCAD5Sj5Ncp8VAEUVa6CafCJfe8nttwCgGFK6aVamGJEDKKrSFDuZIwdQVCndjzxTsT6xACA1pUnk4+N5RwAA2ShNsbOjI+8IACAbpSl2MiIHUFSlGZHHWkEDAIoq+UTO/cgBFFVpip2sEASgqEoztcKanQCKqjQ3zZqczDsCAMhGrBpg8ok81hwSAKSmNIm8rS3vCAAgG6WZWqHYCaCoKHYCQIMrzYg81uKkAJCa5ObIzazJzP5oZk/EalOK94kFAKlJLpFLukfSnojtSWJqBUBxJXXTLDPrl/QRSQ/HaK8WxU4ARdXcHKedWCPyhyTdJ+myEyFmttPMhs1suFKpLLth7rUCoKiSGZGb2R2STrn77sUe5+673H3I3Yd6enqW3T5z5ACwuBgj8lskfdTMDkr6nqQPmNl3I7QribNWABRXMosvu/sD7t7v7oOS7pL0K3f/VN2RzejsjNUSAKQl1kA1+fPIR0fzjgAAshFrRB6pZhq4+28k/SZmm7GqugCQmunpOJfpJz8ij3UvAgAoquTTJIsvAyiq0tw0i2IngKJK5jzyrHFlJ4CiSub0w6zF2lEASE2sFdBI5ACQk9Ik8rGxvCMAgGxQ7ASABleaYienHwIoqtKMyGOtoAEARZV8Iud+5ACKqjTFTm6aBaCoSjO10tGRdwQAkI1YC+ckn8gnJ/OOAACyEasGmHwijzWHBACpKU0ib2vLOwIAyEZppla4aRaAoipNsZMROYCiKs2IPNYlrACQmtLMkZPIARRVaRI555EDKKrS3DSLKzsBFFVzc5x2kk/k3GsFQFGVZkTOBUEAsLi6E7mZDZjZr83sBTN73szuiRFY1dRUzNYAIB2xlrKMMUMzJeled3/azNZJ2m1mT7r7CxHaptgJoLCmpqSWlvrbqXtE7u7H3f3pma/PS9ojqa/edqu4shNAUcUakUedIzezQUnvkPTUAj/baWbDZjZcqVSW3Wasqi4ApCa5KzvNrEvS9yV9yd3Pzf+5u+9y9yF3H+rp6Vl+gMmXYwEgX1HSpJm1KCTxx9z9BzHarGLxZQBFlcxNs8zMJD0iaY+7f7X+kObq7IzdIgCkIaXzyG+R9GlJHzCzZ2b+fThCu5IodgIormROP3T3/5UU6dYvl6LYCaCoYl3wmHwpkWIngKIqTSKn2AmgqJIpdmaNKzsBFFVKxc5MMSIHUFSlGZHHWkEDAIoq+UTO/cgBFFVpip2sEASgqEoztUKxE0BRJXfTrKxMTuYdAQBkI1YNMPlEzlJvAIqqNIm8rS3vCAAgG6WZWqHYCaCoSlPsZEQOoKhKMyKPtaMAkJrSzJGTyAEUVWkSeXt73hEAQDZKc9MsVggCUFSxFs5JPpG3tOQdAQBkozQjci4IAoDFJZ/IuUQfQFHFWnw5+UTe2Zl3BACQjampOO0kn8gpdgIoqtKMyCl2Aiiq0lzZyVJvALC4KInczG43sxfNbL+Z3R+jzSoWXwZQVMncNMvMmiR9U9KHJN0k6ZNmdlO97VZR7ARQVCmdR36zpP3ufsDdJyR9T9KdEdqVRLETQHGlVOzsk3Sk5vuRmW1zmNlOMxs2s+FKpbLsxmNdwgoAqYl1weOqFTvdfZe7D7n7UE9Pz7KfF2sOCQBSk1IiPyppoOb7/pltUVDsBFBUyRQ7Jf1B0g1mtt3MWiXdJenHEdqVJHV0xGoJANISq9hZ9wy0u0+Z2Rcl/VxSk6RH3f35uiObMTERqyUASEusYmeUUqK7/1TST2O0NR8XBAEoqpTmyDPFJfoAiqo0l+hzHjmAokrpPPJMUewEUFSlGZFT7ARQVLFqgMkncpZ6A1BUpUnkra15RwAA2UjpplmZGhvLOwIAyEZpip2MyAEUVWmKnbF2FABSU5o5chI5gKIqTSJvb887AgDIRmmKnVzZCaCoSlPs5F4rAIqqNMVOLggCgMUln8gnJ/OOAACyUZqplc7OvCMAgGxMTcVpJ/lETrETQFGVZkROsRNAUZWm2MlSbwCwuOQT+fh43hEAQDbWRMrAySdyip0AioorOwGgwZWm2BlrRwEgNbEueCSRA0BOkkjkZvYVM/uLmf3JzH5oZhvihDWLFYIAFFUqxc4nJb3F3d8maa+kB+oPaS6KnQCKKolip7v/wt2rF5n+TlJ//SHNNTERu0UASEOKxc7PSfrZ5X5oZjvNbNjMhiuVyrIb5YIgAEW1anPkZvZLM/vzAv/urHnMg5KmJD12+YB9l7sPuftQT0/PsgPkEn0ARRXrEv3mpR7g7rct9nMz+4ykOyTd6h7/7uGjo7FbBIA0xJpaWTKRL8bMbpd0n6S/dfdMUi7FTgBFNT0d58yVepv4hqR1kp40s2fM7N/qD2kuip0AiipWDbCuEbm7vylOGABQPrESefJXdlLsBFBUSZxHvhq4shNAUaV4Hnkm2tryjgAAslGaFYJi/ekBAKkpzRx5rE8sAEhNaRI5UysAiopiJwA0uNIUO1tb844AALJRmmInc+QAsLjkE/nU1NKPAYBGlMoKQZnr6Mg7AgDIRmmKnRcu5B0BAGSjNMVO7rUCoKhKU+xkqTcAWFzyiXx8PO8IACAbpSl2skIQgKIqTbGTKzsBFFVpip2x/vQAgNTEWq4++TQZ6xMLAFJTmkTO1AqAoqLYCQANrjTFzomJvCMAgGyUptgJAEVVmjly7kcOoKiSukTfzO41Mzez7hjt1Rodjd0iAKQhmakVMxuQ9EFJh+sP51IUOwEUVUrFzq9Juk9SpNmeuSh2AiiqJE4/NLM7JR1192eX8didZjZsZsOVSqWelwWAQoh1d9fmpV/Ifimpd4EfPSjpywrTKkty912SdknS0NDQskfvFDsBFNXFi3FG5Usmcne/baHtZvZWSdslPWvhY6Vf0tNmdrO7n6g/tIBiJ4CiilXsXDKRX467Pydpc/V7MzsoacjdT0eI6/+1t8dsDQDSMT0dZ0Se/Hnksaq6AJCaVZsjXy53H4zVVq1YJ8wDQGpiJfLkR+RtbXlHAADZSOk88kxduJB3BACQjWSu7MwaI3IARZXUvVayFOvuYABQVMkn8snJvCMAgGwkcYn+aujoyDsCAMgGxU4AaHClKXY2RzvTHQDSUppiZ6w5JAAoquTT5Ph43hEAQDZKU+xkhSAARVWaYufYWN4RAEA2SlPsZI4cQFHFuuAx+TQZ6xMLAFJTmkROsRNAUZWm2MkKQQCKqjTFTu61AqCoSlPsBICiKs0ceWtr3hEAQDZKc4n+6GjeEQBANkoztcKVnQCKimInADS40px+yFJvAIrKLE47ySdyip0AiiqZqRUzu9vM/mJmz5vZP8cIqhbFTgBFFavYWdf6O2b2fkl3Snq7u4+b2eY4Yc3iyk4ARTU9HWeevN4mviDpn9x9XJLc/VT9Ic0V608PAEhNKnPkOyT9jZk9ZWb/bWbvvtwDzWynmQ2b2XClUln2C/T2Mk8OoHiamuIl8iWnVszsl5J6F/jRgzPP3yjpryW9W9J/mNl17peea+LuuyTtkqShoaFln4vyvveFc8knJpb7DABIW3Oz9LGPreLph+5+m7u/ZYF//ylpRNIPPPi9pGlJ3XFCC1pbpSeekK66Surqmi0O1BYJardVP+Gq29asWd42s9mDuti26vOvJIblxhUzhuXEdbkYFourueajP6sYVrt/YsWQwrGpxrDUsamNNbX+WWlcjdA/ra0hj735zdK3vqVo6ip2SvqRpPdL+rWZ7ZDUKul0vUHNd8st0rFj0k9+Ip07J117rXTwoLRpU5hDP3tW2rZNOnQoJPzmZumVV6TBQenwYWntWqmjQzp5Mjzu2DGppUVav146flwaGJBOnQoHvKdHOnJEuuaa0O7kpLR1a2hnyxbpjTekCxek/v7weps2SVNTIa7BwRDX+vWh4159dTaGrq7QiadPhxiOHpXa2qR166QTJ0J7J0+Gzt+0SRoZCdteeSXsY29viKu3Vzp/PiyBV42huzv8xfL667PHZuPGcA7+a6+FGOYfm23bwmt0dITjc/JkOA4nToTHXH11iLG/P8TsLm3ePHtszpwJx+aaa0LbW7aE4/LGG4v3z/r1YR+X0z8bNoSv+/ulSiX0T3d3iLuvL+zb1NTi/dPdHeI8dy60ffBg2DezxftnZCQU2ru65h6b2v7p6wttXLwYXntkJPx//nzoj76+EENPT+ivN94Ibb/88mz/nDkz973b0jI3hoX6p/rePXYsbKtULu2fs2dDDNX+6e0NZ4DN75/qe3ex/unqCu/VSmX2vdvaGuKt/v6cPBne8/P7p/r7c+TI3P4ZGAgxVN+758/P7R8pPH/79rBt3brZ/hkcDO11dITYTpwI7R0/Ho7Nxo2zvz+nT4eC4pYt4Tlbt4b9nd8/4+Nzf3+yzC07doSZhljTKlL9ifxRSY+a2Z8lTUj6u4WmVWJYu1b6xCeyaBkAGltdidzdJyR9KlIsAIAVSP7KTgDA4kjkANDgSOQA0OBI5ADQ4Cyjk0wWf1GziqRDK3x6tzI4xTEn7Et6irIfEvuSqnr2ZZu798zfmEsir4eZDbv7UN5xxMC+pKco+yGxL6nKYl+YWgGABkciB4AG14iJfFfeAUTEvqSnKPshsS+pir4vDTdHDgCYqxFH5ACAGiRyAGhwDZvIs170ebWZ2b1m5mYW9X7uq8XMvjLTH38ysx+a2Ya8Y7pSZna7mb1oZvvN7P6841kpMxsws1+b2Qszvx/35B1TPcysycz+aGZP5B1LPcxsg5k9PvN7ssfM3hOr7YZM5PMWff4rSf+Sc0h1MbMBSR+UdDjvWOrwpKS3uPvbJO2V9EDO8VwRM2uS9E1JH5J0k6RPmtlN+Ua1YlOS7nX3mxRW7/qHBt4XSbpH0p68g4jg65L+y93fLOntirhPDZnItQqLPq+yr0m6T1LDVp7d/RfuPjXz7e8k9ecZzwrcLGm/ux+YuT3z9xQGCw3H3Y+7+9MzX59XSBh9+Ua1MmbWL+kjkh7OO5Z6mNl6Se+V9IgUbgHu7mditd+oiXzZiz6nzszulHTU3Z/NO5aIPifpZ3kHcYX6JB2p+X5EDZr8apnZoKR3SHoq51BW6iGFQc50znHUa7ukiqTvzEwTPWxma2M1Xu8KQZmJtehzCpbYly8rTKskb7H9mFnDVWb2oMKf9o+tZmy4lJl1Sfq+pC+5+7m847lSZnaHpFPuvtvM3pdzOPVqlvROSXe7+1Nm9nVJ90v6x1iNJ8ndb7vcz8zsC5pZ9FnS782suuhzZbXiuxKX2xcze6vCJ/WzFhbw65f0tJnd7O4nVjHEZVmsTyTJzD4j6Q5Jt6b6obqIo5IGar7vn9nWkMysRSGJP+buP8g7nhW6RdJHzezDktolXWVm33X3RlyVbETSiLtX/zJ6XCGRR9GoUys/Ulj0WVku+pw1d3/O3Te7+6C7Dyp09jtTTOJLMbPbFf4E/qi7j+Ydzwr8QdINZrbdzFol3SXpxznHtCIWRgWPSNrj7l/NO56VcvcH3L1/5nfjLkm/atAkrpnf6SNmduPMplslvRCr/WRH5EtYtUWfsWzfkNQm6cmZvy5+5+5/n29Iy+fuU2b2RUk/l9Qk6VF3fz7nsFbqFkmflvScmT0zs+3L7v7T/EKCpLslPTYzUDgg6bOxGuYSfQBocI06tQIAmEEiB4AGRyIHgAZHIgeABkciB4AGRyIHgAZHIgeABvd//WcmEiQVEVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_points(low, high, num):\n",
    "    result = []\n",
    "    for x in np.linspace(low, high, num):\n",
    "        for y in np.linspace(low, high, num):\n",
    "            result.append([x, y])\n",
    "    return np.array(result)\n",
    "\n",
    "space = torch.from_numpy(create_points(-6, 6, 121)).float()\n",
    "\n",
    "def decision_boundary(net, x):\n",
    "    with torch.no_grad():\n",
    "        y_hat = net(x, u1, v1, b1, u2, v2, b2)\n",
    "        plot_decision_boundary(x, y_hat)\n",
    "        \n",
    "decision_boundary(net, space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
